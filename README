
Slaughter
---------

The goal of this project is to have a lightweight system which will
allow the control and manipulation of multiple systems.

The tasks we support are pretty basic, but they include:

   1.  Replacing a file, literally.
   2.  Replacing a file, expanding content within it.
   3.  Appending lines to files, or commenting out lines.
   4.  Running system commands.
   5.  Testing for the existence of local users, and fetching their details.
   6.  Checking disk space, and mount-points.
   7.  Sending alerts via email.




Overview
--------

We assume that we have a "server" somewhere.  This server is designed to
allow files and policies to be retrieved from it.

This server is nothing more than Apache running HTTP, and each client
will connect to it to download their policies - this means the management
isn't pushed from the central source, instead each client node makes
pull requests.

The attaction of client-pull is that there is no need to maintain state
on the central server, and each client can be trusted to schedule itself
via a cron-like system.  The potential downside is that you might fail to
notice if a client suddenly stops making appropriate requests.


Policies
--------

The list of tasks which each node should carry out is defined in a policy
document.  These policy documents are fetched via HTTP from the server
and may recursively include other policies.

When a client node launches the first thing it will do is attempt to fetch
the policy "default.policy", but you may configure a node to fetch a different
policy if you wish via the "--policy" argument to the slaughter command.

This default policy file can contain code in Perl, and the use of our
additional primitives.  It is expected that because the file default.policy
is fetched by all clients it should be used for house-keeping, and merely
include other policies.

For example this might be a sane default.policy file:

---

# actions to carry out globally
FetchPolicy  global.policy ;

# is there a per-client one?
FetchPolicy $fqdn.policy;

----

In this case the variable "fqdn" is expanded to the fully-qualified
domain-name of the requesting client - this is an example of one of the
many available defined variables clients may make use of in policy
files, or pure perl code.

If the hostname-specific policy file does not exist then it is merely
ignored.



Client Layout
-------------

To get started a client needs to have :

  a.  The slaughter-client package installed upon it.
  b.  The name of the server stored in /etc/slaughter/slaughter.conf

Once this is done cron may be used to ensure that /sbin/slaughter is invoked
upon a regular basis.  (Hourly is a good choice.)

You'll probably want to invoke it manually for the first few times as you're
putting together your policies.



Server Layout
-------------

A webserver should be setup to serve content from a particular root directory.

The root directory might look like like this:

           /var/www/slaughter/
           /var/www/slaughter/policies/
           /var/www/slaughter/files/

e.g. The request for http://$master/slaughter/policies/default.policy should
succeed.

In the interests of security it is probably wise to limit access to the
/slaughter/ location, denying access to clients you're not expecting to
pull from it.




In Depth Operation
------------------

The client node will first fetch the policy, which might contain
recursive calls to include other policies via "FetchPolicy path ;".

Once the (recursive) fetching has been completed the downloaded
content will be wrapped such that it becomes a locally executable file,
making use of the Slaughter.pm module (this module is where the primitives
are implemented and exported to the perl script).

Finally the locally written script will be made executable and
directly executed, before being removed.

The output of the script will be saved to a logfile.

Steve
--
